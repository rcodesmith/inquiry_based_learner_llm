from itertools import chain
import json
from typing import Iterable, TypedDict, cast

from anthropic.types import Message, MessageParam

from genai_wb import claude_api
from genai_wb.genai_conversation import GenAIConversation

JSON_FORMAT = """{
  "questions": [{
      "question": "string",
      "reasoning": "string"
  }]
}"""

INTERVIEW_SYSTEM_PROMPT_QAS_FRAGMENT = """

Following are prior questions you have been asked, and answers you gave in JSON format, delimetered by three dollar signs:
$$$
%(learning_qas)s
$$$
"""
class Question(TypedDict):
    question: str
    reasoning: int

class QuestionAnswer(TypedDict):
    question: str
    answer: str

class InquiryBasedLearner:
    """
    Class implementing an Inquiry-based LLM learner.

    It includes two LLM conversations - one for learning from a user via questions and answers, and one for interviewing a model representing the user
    which has learned from the prior questions and answers.
    These two conversations have different system prompts, and play different roles.

    During the learning phase, questions are generated by the model (the learner) and answered by a person.  These questions and
    answers then get added to the knowledge base for the second model to use during the interview phase.
    """
    learning_conversation : GenAIConversation
    interview_conversation : GenAIConversation | None
    interview_system_prompt : str
    genai : claude_api.GenAI

    learning_qas : list[QuestionAnswer] = []

    def __init__(self, genai: claude_api.GenAI, learning_system_prompt: str, interview_system_prompt: str):
        self.genai = genai
        self.learning_conversation = GenAIConversation(self.genai, learning_system_prompt)
        self.interview_system_prompt = interview_system_prompt
        #self.interview_conversation = GenAIConversation(self.genai, interview_system_prompt)

    def learning_generate_questions(self, questions_request_prompt: str, temperature: float = 1.0) -> list[Question]:
        
        prompt = f"""{questions_request_prompt}

        Don't ask questions which have been asked of the candidate before.
        Following are prior questions which have been asked of the candidate before, and the answers in JSON format, delimetered by three dollar signs:
$$$
%(learning_qas)s
$$$

Format your response as a JSON object with the structure provided below:

JSON Structure: {JSON_FORMAT}

Ensure your response is a valid JSON object that can be parsed. Do not include any explanatory text outside the JSON structure.
"""
        msg = self.learning_conversation.messages_create(user_text=prompt, temperature=temperature)
        questions = cast(list[Question], claude_api.extract_json(msg))

        return questions


    def learning_answer_question(self, question: str, answer: str):

        self.learning_qas.append({"question": question, "answer": answer})
        self.interview_conversation = None

    def interview_answer_question(self, question: str, temperature: float = 1.0) -> str:

        if self.interview_conversation is None:
            learning_qas_json = json.dumps(self.learning_qas)
            interview_system_prompt = self.interview_system_prompt + (INTERVIEW_SYSTEM_PROMPT_QAS_FRAGMENT % {'learning_qas': learning_qas_json})
            self.interview_conversation = GenAIConversation(self.genai, interview_system_prompt)

        msg = self.interview_conversation.messages_create(user_text=question, temperature=temperature)
        return claude_api.extract_text(msg)

        return answer